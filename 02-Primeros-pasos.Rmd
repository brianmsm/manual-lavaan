# Primeros pasos en el Análisis

Empezaremos con un primer análisis utulizando una base de datos de acceso libre y de las más difundidas para el AFC. Se trata de la BD de @holzinger1939 que recolecta información de una prueba de Habilidades Cognitivas conformado por 26 test en séptimo y octavo grado de dos colegios diferentes (Pasteur y Grant-White). Para este procedimiento se utilizará los datos recortados a 9 pruebas que se estructuran en 3 factores latentes: Visual, Textual y Velocidad.

(ref:holzinger-estructura) Estructura de la prueba de @holzinger1939.

```{r holzinger-estructura, echo=FALSE}
knitr::kable(data.frame(
  Factores = c("Factor Visual", "Factor Textual", "Factor Velocidad"),
  `Indicadores` = c("X1, X2 y X3", "X4, X5 y X6", "X7, X8 y X9"),
  stringsAsFactors = FALSE, check.names = FALSE
), caption = '(ref:holzinger-estructura)', booktabs = TRUE, align=rep('c', 5))
```

Es importante conocer la estructura propuesta del instrumento a analizar (Table \@ref(tab:holzinger-estructura)) debido a que el ajuste de los modelos calculados requieren tener un marco explicativo y referencial.

## Importar datos y reconocer variables

Empezaremos con algunas funciones sencillas que nos ayuden a entender la forma de trabajo de R previo al flujo de análisis de AFC propiamente. En caso de no haber cargado aún el paquete, o solo necesitar una función única del mismo, podrías solicitarlo mediante la indicación:

       package::function(...)

Lo indicado arriba estará solicitando una función **function** del paquete **package** de forma específica. ¡Probemos!

```{r echo=TRUE}
# Solicitamos ver la BD
head(lavaan::HolzingerSwineford1939)
# ¡Quiero orden!
tibble::as_tibble(lavaan::HolzingerSwineford1939) 
```

Hemos realizado dos formas de poder visualizar los datos. Definitivamente la segunda manera nos permite visualizar los datos de forma ordenada. Antes de ir al análisis, necesitamos que R guarde estos datos en un **objeto**, es decir un nombre que permita identificarlo (lo veremos en el *ambiente* [Environment]). Para ello necesitamos utilizar la designación "<-" (alt + -) como lo veremos abajo.

```{r echo=TRUE}
# Guardaremos la BD
datos <- tibble::as_tibble(             # Guardemos la BD en "data"
    lavaan::HolzingerSwineford1939     # Esta es la BD
    ) 
View(datos)
```

¡Muy bien! Lo hemos logrado. Si vemos al recuadro superior derecho, podemos ver que en el entorno "ambiente" ahora aparece "data" indicando que posee 301 observaciones y 15 variables. Podemos tener más información si lo que queremos es focalizarnos en
las variables. Podemos usar la función *names* para tener un listado de las variables de un data.frame (BD) y la función **glimpse** del paquete **dplyr** para ver las propiedades de las variables (además del listado del mismo).

```{r echo=TRUE}
names(datos)             # Listado de variables
dplyr::glimpse(datos)    # Listado y propiedades de variables
```

¡Perfecto! Hemos cargado una base de datos y reconocido el contenido de los datos que vamos a utilizar. **¡Estamos listos para empezar con la acción!**

## Sintaxis de Lavaan (Especificación)

Lo primero que haremos es especificar el modelo (estructura factorial) de la prueba tal y como se encuentra indicado en la Tabla \@ref(tab:holzinger-estructura). ¿Cómo especificamos? ¡Simple! Solo debemos indicarle a R qué variables forman los factores (variables latentes) y la relación que hay entre los mismos. Para indicar las relaciones existentes se tiene las siguientes indicaciones de la Tabla \@ref(tab:sintaxis-lavaan):

(ref:sintaxis-lavaan) Sintaxis para la Especificación en Lavaan.

```{r sintaxis-lavaan, echo=FALSE}
knitr::kable(data.frame(
  Sintaxis = c("=~", "~", "~~", "~ 1"),
  `Descripción` = c("Conformación de una variable latente", "Regresión", "Co-varianza entre errores o varianza del indicador", "Interceptos"),
  stringsAsFactors = FALSE, check.names = FALSE
), caption = '(ref:sintaxis-lavaan)', booktabs = TRUE)
```

Para la especificación de un AFC nos interesa indicarle a R las variables latentes y su conformación (=~) y la co-varianza entre los errores (~~) principalmente (o al menos por el nivel básico explorado). ¡Vamos a ello!

```{r echo=TRUE}
# Se crea un objeto "model" donde se almacena la información
# acerca de la especificación del instrumento
model <-  " visual  =~ x1 + x2 + x3
            textual =~ x4 + x5 + x6
            speed   =~ x7 + x8 + x9 "
```

¡Así de simple! Se está creando un objeto llamado *model* que usaremos para solicitarle a R que identifique el modelo y realice la estimación del mismo. Esta especificación precisa que existen tres factores **visual**, **textual** y **speed** que se encuentran conformados por 3 indicadores cada uno. 

## Identificación, Estimación y Evaluación

¡Ahora vamos a identificar y estimar! ¡Si! Los dos pasos al mismo tiempo utilizando la función **cfa** del paquete **lavaan**.

```{r echo=TRUE}
# Cargamos el paquete
library(lavaan)
# Almacenamos en el objeto "fit" la información de la estimación
fit <- cfa(model = model,
           data  = datos)
```

¡Ya está! Veamos el entorno *ambiente*. Hemos creado un objeto adicional de clase *lavaan* llamado **fit**. La función **cfa** es un wrapper de la función general *lavaan*, es decir que automatiza una gran cantidad de especificaciones como las varianzas individuales de las variables, correlaciones de errores establecidas a 0, y el hecho de tratar a los factores especificados como *oblicuos*, es decir que se encuentra correlacionados entre ellos.
Dicho esta aclaración sobre lo que acabamos de hacer, procederemos a verificar la evaluación de nuestro modelo factorial almacenado en **fit**. Para esto usaremos a la conocida función **summary** que nos devolverá de forma *organizada* parte de lo estimado. ¡Hagámoslo!

```{r echo=TRUE}
summary(datos) ## ¡Ups! Nos confundimos, parece ser que hace eso mismo: ¡Resumir!
## Muestrame acerca de lo estimado entonces
summary(fit)  
```

¡Que elegancia! No nos asustemos. Vamos a entenderlo paso a paso, de las manitos. No nos soltemos. Respiremos y empecemos por la primera parte. Vemos que el "output" (resultados en consola) nos indica la versión de "lavaan", el número de parámetros libres que tenemos en el modelo, número de casos analizados, método de estimación utilizado (máxima verosimilitud), valor de chi cuadrado (Model Fit Test Statistic), grados de libertad (sobre identificado), valor p de la prueba de bondad de ajuste (chi cuadrado) e información adicional que por ahora no será de nuestra preocupación.

En el apartado de "Latent Variables" (Variables Latentes) podemos ver la estimación sin estandarizar de los indicadores frente a la variable latente, erores estándares de la estimación, valor Z y valor p del mismo. Con respecto al apartado "Covariances", sigue la misma estructura que arriba centrándose en las relaciones entre factores (variables latentes). Recordemos que al usar la función "cfa" por defecto se configura en "oblicuo" (factores correlacionados). Por último, en el apartado de las varianzas lo único de lo que nos preocuparemos por ahora es el no encontrar valores estimados (no se encuentran estadarizados) que sean positivos. En caso de encontrar uno negativo, estaremos frente a un caso Heywood!

Es probable que esta explicación, a pesar de mantenerse de forma simple, te haya parecido algo compleja. Es normal sentirlo de esa forma si recién estás teniendo contacto con este tipo de análisis. Te alegrará saber que, aunque hay mucha información para ver y revisar, a lo que debemos prestar atención es a los índices de ajuste del modelo y a las estimaciones estandarizadas. Será lo principal. ¡Espera! ¿Y donde se encuentra todo eso?

Calma, toda esta información se encuentra almacenada en el objeto "fit", solo que al momento de solicitar el "output" con la función "summary", no hemos sido más precisos en lo que queremos que nos muestre. Para las dos menciones que deseamos poder ver y revisar usaremos dos argumentos adicionales. Si deseamos que se adicione la información sobre índices de ajuste, la función quedará así:

    summary(..., fit.measures = TRUE)
    
Si deseamos que se adicione información estandarizada, la función quedará así:

    summary(..., standardized = TRUE)

Así, en caso de querer ambas cosas, solo hará falta poner esos dos argumentos en la misma solicitud:

    summary(..., fit.measures = TRUE, standardized = TRUE)
    
¡Probemos!

```{r echo=TRUE}
# Solicitar el resumen del análisis adicionando las medidas estandarizadas 
# y los índices de ajuste
summary(fit, fit.measures = TRUE, standardized = TRUE)
```

Está bien, no hay problema. Solo se agregaron unas líneas más al "output". ¡Podemos manejarlo! En la primera parte del "output" se adicionó cuatro de los índices de ajuste más comunes: CFI (>= .95), TLI (>= .95), RMSEA (<= .05) y SRMR (<= .06).

Estos índices de ajuste nos permitirán decidir si, el modelo tal y como se encuentra especificado guarda coherencia estadística. En la parte de abajo (Latent Variables, Covariances y Variances) se ha agregado dos columnas *Std.lv* y *Std.all*. Nosotros nos concentraremos en "Std.all" debido a que representa la estimación estandarizada a todo el modelo (varía entre -1 y 1). Mientras más alto mejor. 

Antes de pasar a ver como podemos mejorar nuestro modelo ya que presenta valores en sus ajustes que no llegan a ser del todo satisfactorios, veremos otra forma de visualizar los resultados que puede ser un tanto más amigable.

## Re-Especificación

Vemaos como mejorar nuestro modelo ya que presenta valores en sus ajustes que no llegan a ser del todo satisfactorios. En este punto, la reflexión teórica debería darnos algunas pistas sobre el mal funcionamiento de algunos ítems, pertenencia a otro factor o presencia de correlación de errores por un mismo comienzo en el enunciado.

Los índices de modificación son valores que nos brindarán una **orientación** acerca de la re-especificación de la estructura factorial evaluada inicialmente. Para ello usaremos la siguiente función:

      `modificationindices(fit)`

Veremos también cómo ver solo una parte de los IM (los más representativos)

```{r echo=TRUE}
# Solicitar los 10 primeros IM con valores más altos
modindices(fit, sort = TRUE, maximum.number = 10)  
```

Los índices de modificación representan la disminución en el valor de chi-cuadrado que se produciría en caso se realizará lo sugerido. ¿Cómo saber cuando es importante? Va a depender de cada análisis, es distinto un modelo estructural con chi-cuadrado de 1500 de valor que presenta IM de 35 puntos; que un modelo estructural de chi-cuadrado 65 con el mismo valor en IM.

Esta información se adiciona al "expected parameter change" (epc) y su valor estandarizado (sepc.all) para tener mayor noción del cambio a nivel estadístico que se realizaría. 

Antes de hacer caso a la sugerencia propuesta, **RECORDAR**, siempre debe primar el criterio metodológico. En caso de sugerir correlación de errores entre ítems, seguir estas sugerencias:

a) Buscar similitud en el contenido de ambos ítems que pueda haber propiciado una similar forma de producir error en la medición.
b) Verificar si los ítems comparten una misma forma de finalizar o iniciar el enunciado.
c) Si los items pertenecen a diferentes factores, tener mucho cuidado. Existe la posibilidad de que lo señalado como sugerencia solo se deba a aleatoridad en los datos. Si es que pese a ello se encontrase relación o motivos para suponer errores correlacionados entre dichos ítems, poner en alerta la integridad de la estructura factorial de la prueba.

Con respecto a las sugerencias de que un ítem pertenezca a otro factor, tener en cuenta los siguientes puntos:

a) Existe la posibilidad de que un ítem verdaderamente deba pertenecer a otro factor. Generalmente sucede esto en pruebas nuevas o con pocos estudios psicométricos. 
b) De igual manera a la anterior condición, su señalamiento puede deberse a pura aleatoridad estadística.
c) Si un mismo ítem aparece repetidamente en los IM y se sugiere que podría suponer un cambio importante en chi-cuadrado si se realizase la sugerencia, se debe tener en alerta a dicho ítem. Su exclusión del análisis puede mejorar la estructura factorial.

Dicho lo anterior verificamos que los IM sugieren que habría un cambio de 36 puntos menos en el chi-cuadrado (valor actual de 85.3) si se modificase su pertenencia al factor visual. Mientras que si se correlaciona los errores del indicador 7 y 8, habría un cambio de 34.15, además de que la correlación sería de 0.86 (sepc.all).

Recordemos que cada vez que se realiza una re-especificación en el modelo los IM cambian debido a que el ajuste del modelo también cambia. Así que no se recomienda hacer múltiples re-especificaciones a partir de un solo procedimiento de análisis para re-especificar. De uno en uno o de dos en dos si las incongruencias son más claras.

Para efectos de aprendizaje, incluiremos una correlación de errores entre el indicador 7 y 8 para ver cómo se produce los cambios. Previo a ello guardaremos los índices de ajuste en un objeto que servirá para ir comparando los cambios realizados.
      
```{r echo=TRUE}
# Procederemos a re-especificar creando un objeto con nombre "model_02"
model_02 <- " # Modelo de medición
              visual  =~ x1 + x2 + x3
              textual =~ x4 + x5 + x6
              speed   =~ x7 + x8 + x9 
              # Correlación de errores          
              x7 ~~ x8
            "
```

Hemos agregado la re-especificación de la correlación entre errores.
**¡Estimemos nuevamente y veamos los resultados!**

```{r echo=TRUE}
# Procederemos a re-especificar creando un objeto con nombre "model_02"
fit_02 <- cfa(model = model_02, 
              data  = datos)
summary(fit_02, fit.measures = TRUE, standardized = TRUE)
```

A simple vista podemos ver una mejora importante en los índices de ajuste del modelo estimado. Ordenemos los datos y veamoslo en paralelo para entenderlo mejor.

```{r echo=TRUE}
# Guardando los índices en objetos
library(dplyr)
fit_index <- broom::glance(fit) %>% 
    select(chisq, npar, cfi, tli, rmsea, rmsea.conf.high, srmr, aic, bic, estimator)
fit_index02 <- broom::glance(fit_02) %>% 
    select(chisq, npar, cfi, tli, rmsea, rmsea.conf.high, srmr, aic, bic, estimator)
# Uniendo 
bind_rows(fit_index, fit_index02, .id = "Modelo")
```

¡Listo! Estamos viendo que el modelo 2 muestra una mejora importante en la estructura factorial de la prueba. Es decir, tener en consideración que los errores de indicador **7** y **8** se encuentran correlacionados permite un mejor ajuste en lo mostrado por la matriz de covarianza empírica y la teórica (especificado).

Antes de cantar victoria, volvamos a verificar los IM para ver si hay más cambios importantes sugeridos al modelo.

```{r echo=TRUE}
# Solicitar los 10 primeros IM con valores más altos
modindices(fit_02, sort = TRUE, maximum.number = 10)  
```

Genial, parece ser que los IM mostrados no son tan altos ni el **sepc.all** representa un cambio importante al modelo estimado. Tenemos entonces un modelo estructural comprobado... ¡Espera! ¿Hemos revisado la distribución
de los datos? Ups... Verifiquemos si se tiene una distribución normal
multivariada. Para ello usaremos la función "mvn" del paquete "MVN".



